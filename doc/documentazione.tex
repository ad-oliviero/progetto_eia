\documentclass{article}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{biblatex}
\usepackage{listings}
\geometry{a4paper, margin=1in}

\addbibresource{references.bib}

\pagestyle{fancy}
\fancyhf{}

\title{Documentazione del Progetto di Intelligenza Artificiale}
\author{Adriano Oliviero N46006115}
\date{2 Luglio 2024}

\fancyfoot[L]{Intelligenza Artificiale}
\fancyfoot[C]{Adriano Oliviero N46006115}
\fancyfoot[R]{\thepage}
\renewcommand{\footrulewidth}{0.1pt}

\begin{document}

\maketitle

\newpage
\tableofcontents
\newpage
\section{Obiettivo del progetto}
Il progetto si propone di applicare algoritmi di ricerca ad alcuni dataset disponibili su
\url{https://snap.stanford.edu/data/} per valutare l'efficacia e l'efficienza di tali algoritmi.

\section{Descrizione delle metodologie e tecniche adoperate}
\subsection{Il linguaggio}
Per la realizzazione del progetto, ho utilizzato il linguaggio di programmazione Rust.

Questo linguaggio è stato scelto per diversi motivi:
\begin{itemize}
	\item \textbf{Performance}: È un linguaggio di programmazione ad alte prestazioni con gestione automatica della memoria.
	\item \textbf{Semplicità}: È moderno con una sintassi pulita e concisa, compatibile con alti livelli di astrazione, più difficile da scrivere rispetto a Python, ma più facile di C/C++.
	\item \textbf{Esperienza}: Ho già esperienza con Rust e ho trovato che sia un linguaggio adatto per progetti di questo tipo.
\end{itemize}

\subsection{Software di profilazione}
Al fine della valutazione dell'efficienza degli algoritmi, ho scelto di misurare il tempo di esecuzione degli stessi
utilizzando la libreria \texttt{std::time} di Rust.

In aggiunta a questa metrica, ho scelto di misurare anche la quantità
di memoria utilizzata dagli algoritmi, utilizzando un software esterno al progetto: \texttt{valgrind} con il tool \texttt{massif}.
Tuttavia, tali tool, generano un enorme overhead, infatti l'esecuzione dei cinque algoritmi sui sette dataset (35 esecuzioni),
ha richiesto precisamente 8 ore, 54 minuti e 53 secondi.
Ho quindi deciso di eseguire \texttt{run.py} una volta per generare i grafici, ed una seconda volta, disattivando \texttt{valgrind},
per generare degli output che rendessero giustizia agli algoritmi.
Questa seconda esecuzione ha richiesto **AGGIORNARE**

Per la generazione dei grafici che si basano sui dati ottenuti dalle misurazioni con \texttt{valgrind},
ho utilizzato la libreria \texttt{matplotlib} di Python.

\subsection{Organizzazione del progetto}
Il progetto è organizzato come segue:
\begin{itemize}
	\item \texttt{src/} - Directory contenente il codice sorgente in Rust, nel quale sono effettivamente implementati gli algoritmi.
	\item \texttt{run.py} - Script Python per eseguire il progetto, e generare benchmark e grafici.
	\item file aggiuntivi
\end{itemize}

\subsection{Compilazione ed esecuzione}
Per compilare ed eseguire il progetto, è necessario avere Rust --e il suo package manager, Cargo-- installati sul proprio sistema.
Inoltre è necessario scaricare almeno un dataset, come descritto nella \hyperref[sec:dataset]{sezione dedicata}.
\vspace*{1em}

Se le dipendenze sono soddisfatte, è possibile procedere con la compilazione ed esecuzione del progetto:
\lstset{
	basicstyle=\ttfamily,
	columns=fullflexible,
	breaklines=true,
	postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
	language=bash
}
\begin{itemize}
	\item Al fine di compilare il progetto, è possibile eseguire il seguente comando:

	      \lstinline[language=bash]|$ cargo build --release|

	\item Al fine di eseguire il programma compilato, è possibile eseguire il seguente comando:

	      \lstinline[language=bash]|$ ./target/release/eia <opzioni>|
\end{itemize}

Se si desidera consultare una lista delle opzioni disponibili, è possibile eseguire il programma con il flag \texttt{-h} o \texttt{--help}:

\lstinline[language=bash]|$ ./target/release/eia --help|
\vspace*{1em}

Inoltre, è possibile eseguire lo script Python fornito per avviare automaticamente alcuni o tutti
gli algoritmi alcuni o tutti i dataset, e generare grafici e benchmark:

\lstinline[language=bash]|$ python3 run.py <lista dei dataset> <lista degli algoritmi>|





\newpage
\subsection{Strutture dati}
Per rendere utilizzabili i dataset, ho implementato le seguenti strutture dati:
\begin{itemize}
	\item \texttt{State: u32} - Un semplice alias per rendere più leggibile il codice.
	\item \texttt{Action} - Struttura dati per rappresentare un'azione:
	      \begin{itemize}
		      \item \texttt{risultato: State} - Stato risultante dall'azione.
		      \item \texttt{costo: i32} - Costo dell'azione.
	      \end{itemize}
	\item \texttt{Node} - Struttura dati per rappresentare un nodo del grafo:
	      \begin{itemize}
		      \item \texttt{stato: State} - Stato corrispondente al nodo.
		      \item \texttt{azioni: Vec<Action>} - Azioni possibili dal nodo.
		      \item \texttt{genitore: Node} - Nodo genitore, utile per risalire il percorso.
		      \item \texttt{costo\_cammino: i32} - Costo del cammino partendo dal nodo iniziale per raggiungere il nodo.
		      \item \texttt{profondita: usize} - Profondità del nodo rispetto al nodo iniziale.
	      \end{itemize}
	\item \texttt{Graph} - Struttura dati contenente una astrazione del grafo:
	      \begin{itemize}
		      \item \texttt{gtype: String} - Tipo del grafo (direzionato, non direzionato o con pesi).
		      \item \texttt{nodi: Vec<Node>} - I nodi del grafo.
		      \item \texttt{edge\_count: u32} - Il numero di archi del grafo, utile per essere sicuri che il caricamento del dataset sia avvenuto correttamente.
		      \item \texttt{load\_dataset(dataset\_path)} - Legge il file del dataset e costruisce il grafo.
	      \end{itemize}
	\item \texttt{Problem} - Struttura dati contenente il grafo e i dati e le funzioni necessarie per la ricerca:
	      \begin{itemize}
		      \item \texttt{stato\_inziale: State} - Nodo dal quale iniziare la ricerca.
		      \item \texttt{stato\_finale: State} - Nodo da raggiungere.
		      \item \texttt{grafo: Graph} - Struttura dati contenente il grafo.
		      \item \texttt{limite: usize} - Limite di profondità per gli algoritmi di ricerca limitata.
		      \item \texttt{goal\_test(\&self, stato) -> bool} - Funzione per verificare se il nodo obiettivo è stato raggiunto.
		      \item le funzioni di ricerca, delle quali parlerò più avanti.
	      \end{itemize}
\end{itemize}
\newpage
\subsection{Algoritmi di ricerca}
Gli algoritmi di ricerca che ho scelto di implementare sono:
\begin{itemize}
	\item \textbf{Tree Search (tree-search)} - Ricerca semplice, per default disattivata a causa della sua eccessiva inefficienza.
	\item \textbf{Breadth-First Search (breadth-first)} - Ricera in ampiezza.
	\item \textbf{Uniform-Cost Search (uniform-cost)} - Ricerca a costo uniforme. Differisce dal Breadth-First Search esclusivamente nel caso di grafi pesati.
	\item \textbf{Depth-Limited Search (depth-limited)}\footnote{test} - Ricerca in profondità limitata.
	\item \textbf{Iterative Deepening Depth-First Search (iterative-deepening)} - Ricerca in profondità iterativa.
	\item \textbf{Bidirectional Search (bi-directional)} - Ricerca bidirezionale.
\end{itemize}

Tutti gli algoritmi sono compatibili sia con grafi direzionati che non direzionati, e con grafi pesati.



\section{Dataset}\label{sec:dataset}
I dataset utilizzati sono stati scaricati dal sito dell'università di Stanford (\url{https://snap.stanford.edu/data/}).
Per scaricare i dataset, è possibile procedere manualmente recandosi alle reciproche pagine sul sito, oppure utilizzare lo script shell fornito nel progetto:
\begin{lstlisting}
  $ chmod +x ./download-datasets.sh
  $ ./download-datasets.sh
\end{lstlisting}
Lo script utilizza \texttt{wget} ed è scritto per sistemi UNIX \& UNIX-like.

\subsection{Dataset Utilizzati}
\begin{table}[h]
	\centering
	\begin{tabular}{|l|r|r|l|r|}
		\hline
		Nome                                                                                      & Nodi    & Archi    & Tipologia       & Dimensione \\
		\hline
		\href{https://snap.stanford.edu/data/soc-sign-bitcoin-alpha.html}{soc-sign-bitcoin-alpha} & 3783    & 24186    & Con pesi        & 152KB      \\
		\href{https://snap.stanford.edu/data/email-Enron.html}{email-Enron}                       & 36692   & 183831   & Non direzionato & 1.1MB      \\
		\href{https://snap.stanford.edu/data/com-Youtube.html}{com-Youtube}                       & 1134890 & 2987624  & Non direzionato & 11MB       \\
		\href{https://snap.stanford.edu/data/roadNet-CA.html}{roadNet-CA}                         & 1965206 & 2766607  & Direzionato     & 18MB       \\
		\href{https://snap.stanford.edu/data/as-Skitter.html}{as-Skitter}                         & 1696415 & 11095298 & Non direzionato & 33MB       \\
		\href{https://snap.stanford.edu/data/cit-Patents.html}{cit-Patents}                       & 3774768 & 16518948 & Direzionato     & 85MB       \\
		\href{https://snap.stanford.edu/data/com-LiveJournal.html}{com-LiveJournal}               & 3997962 & 34681189 & Non direzionato & 124MB      \\
		\hline
	\end{tabular}
	\caption{Dataset Utilizzati}
\end{table}

I dataset contengono alcune informazioni nelle prime righe. Sono in formato \texttt{txt}
con compressione \texttt{.gz} e le proprie righe sono formate da due numeri (Nodo Sinistro
e Nodo Destro), ad eccezione del dataset
\href{https://snap.stanford.edu/data/soc-sign-bitcoin-alpha.html}{soc-sign-bitcoin-alpha},
che è in formato \texttt{csv} con le colonne:
\begin{itemize}
	\item \textbf{SOURCE} (id del nodo Sinistro),
	\item \textbf{TARGET} (id del nodo Destro),
	\item \textbf{RATING} (il costo delle azioni),
	\item \textbf{TIME} (non rilevante).
\end{itemize}

\section{Risultati sperimentali}
I risultati ottenuti sono stati valutati in termini di efficacia ed efficienza, come descritto di seguito.

Inoltre, sono stati generati grafici automaticamente dallo script Python fornito nel progetto.
È possibile visualizzarli nel documento \href{run:grafici.pdf}{grafici.pdf}


\input{risultati.tex}

\section{Codice Sviluppato}
Il codice sviluppato è stato consegnato insieme alla documentazione del progetto e può essere consultato nei file allegati.

Alternativamente è possibile trovare il codice sorgente su GitHub al seguente indirizzo:

\href{https://github.com/ad-oliviero/progetto_eia}{ad-oliviero/progetto\_eia}

\newpage
\nocite{kumar2016edge,kumar2018rev2,jleskovec2009community,klimmt2004introducing,yang2012defining,leskovec2005graphs}
\printbibliography

\end{document}

